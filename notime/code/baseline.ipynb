{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOKnNSACYU0-"
   },
   "source": [
    "# LGU+ 경진대회 - 베이스라인  \n",
    "- [Neural Collaborative Filtering(NCF)](https://arxiv.org/pdf/1708.05031.pdf) 논문의 NeuMF를 참고하여 side-information을 결합한 모델을 PyTorch로 구현\n",
    "- 구현된 모델의 검증 데이터셋과 리더보드의 성능을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차 \n",
    "- 데이터 전처리 \n",
    "    - 기본 설정\n",
    "    - 데이터 불러오기 \n",
    "    - 학습 및 검증 데이터 생성 \n",
    "- NeuMF 구현    \n",
    "    - 모델 구현 \n",
    "    - 학습 및 추론 코드 구현\n",
    "- 모델 학습 \n",
    "    - 하이퍼파라미터 설정 & 최적화 기법 설정\n",
    "    - 모델 학습 \n",
    "    - 학습 과정 시각화 \n",
    "- 제출 \n",
    "    - 모든 유저에 대해 추천 결과 생성\n",
    "    - 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n",
      "8500\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07lHW5CAYU1F"
   },
   "source": [
    "## 데이터 전처리\n",
    "### 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iHstgRfiYU1G"
   },
   "outputs": [],
   "source": [
    "# 패키지 로드\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import os, random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import normal_\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import plotnine\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 \n",
    "class cfg: \n",
    "    gpu_idx = 0\n",
    "    device = torch.device(\"cuda:{}\".format(gpu_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "    top_k = 25\n",
    "    seed = 42\n",
    "    neg_ratio = 100\n",
    "    test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5GrHkU7AYU1I"
   },
   "outputs": [],
   "source": [
    "# 시드 고정 \n",
    "def seed_everything(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "seed_everything(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "data_path = '../data'\n",
    "saved_path = './saved'\n",
    "output_path = './submission'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huw6BwpTYU1J"
   },
   "source": [
    "### 데이터 불러오기\n",
    "- history_data : 시청 시작 데이터\n",
    "- profile_data : 프로필 정보 \n",
    "- meta_data : 콘텐츠 일반 메타 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "A23qw5LXYU1M"
   },
   "outputs": [],
   "source": [
    "# 데이터 불러오기 \n",
    "history_df = pd.read_csv(os.path.join(data_path, 'history_data.csv'), encoding='utf-8')\n",
    "profile_df = pd.read_csv(os.path.join(data_path, 'profile_data.csv'), encoding='utf-8')\n",
    "meta_df = pd.read_csv(os.path.join(data_path, 'meta_data.csv'), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRnh1wEiYU1M"
   },
   "source": [
    "### 학습 및 검증 데이터 생성 \n",
    "- train : 시청 이력의 80%를 사용 \n",
    "- valid : 시청 이력의 20%를 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 (중복제거) \n",
    "# 참고 : drop_duplicates의 subset을 무엇으로 구성하냐에 따라서 제거되는 항목들이 다름 \n",
    "# ex) 'profile_id', 'album_id' : 중복된 시청이력 모두 제거 / 'profile_id', 'album_id', 'log_time' : 같은 시간에 시청한 이력만 제거 \n",
    "data = history_df[['profile_id', 'log_time', 'album_id']].drop_duplicates(subset=['profile_id', 'album_id', 'log_time']).sort_values(by = ['profile_id', 'log_time']).reset_index(drop = True)\n",
    "data['rating'] = 1\n",
    "\n",
    "cfg.n_users = data.profile_id.max()+1\n",
    "cfg.n_items = data.album_id.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 크기: (719401, 4)\n",
      "검증 데이터 크기: (179851, 4)\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 검증 데이터 분리\n",
    "train, valid = train_test_split(\n",
    "    data, test_size=cfg.test_size, random_state=cfg.seed,\n",
    ")\n",
    "print('학습 데이터 크기:', train.shape)\n",
    "print('검증 데이터 크기:', valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd57f70a17b44e78b7c4c8a902a72d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 형태: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix 형태로 변환 \n",
    "train = train.to_numpy()\n",
    "matrix = sparse.lil_matrix((cfg.n_users, cfg.n_items))\n",
    "for (p, _, i, r) in tqdm(train):\n",
    "    matrix[p, i] = r\n",
    "    \n",
    "train = sparse.csr_matrix(matrix)\n",
    "train = train.toarray()\n",
    "print(\"train 형태: \\n\", train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id 3의 age 정보 : 5\n"
     ]
    }
   ],
   "source": [
    "# 유저 특징 정보 추출 \n",
    "profile_df = profile_df.set_index('profile_id')\n",
    "user_features = profile_df[['age']].to_dict()\n",
    "print(\"user_id 3의 age 정보 :\", user_features['age'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "album_id 749의 genre_mid 정보 : 1\n"
     ]
    }
   ],
   "source": [
    "# 아이템 특징 정보 추출 \n",
    "meta_df = meta_df.set_index('album_id')\n",
    "\n",
    "# 범주형 데이터를 수치형 데이터로 변경 \n",
    "le = LabelEncoder()\n",
    "meta_df['genre_mid'] = le.fit_transform(meta_df['genre_mid'])\n",
    "item_features = meta_df[['genre_mid']].to_dict()\n",
    "print(\"album_id 749의 genre_mid 정보 :\", item_features['genre_mid'][749])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출한 특징 정보의 속성을 저장 \n",
    "cfg.n_genres = meta_df['genre_mid'].nunique()\n",
    "cfg.n_continuous_feats = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REzvMyWZYU1S"
   },
   "source": [
    "## NeuMF 구현\n",
    "\n",
    "\n",
    "### 모델 구현 \n",
    "- [Neural Collaborative Filtering(NCF)](https://arxiv.org/pdf/1708.05031.pdf) 논문의 NeuMF를 참고하여 side-information을 결합한 모델을 PyTorch로 구현\n",
    "    - continuous feature (age)와 categorical feature (genre_mid)를 같이 학습할 수 있도록 결합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://drive.google.com/uc?export=view&id=1tpajTLipLoFdvLICO-alAxeoKAE8-k61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hWOt2J5nYU1U"
   },
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    \"\"\"Neural Matrix Factorization Model\n",
    "        참고 문헌 : https://arxiv.org/abs/1708.05031\n",
    "\n",
    "    예시 :\n",
    "        model = NeuMF(cfg) \n",
    "        output = model.forward(user_ids, item_ids, [feat0, feat1]) \n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            cfg : config 파일로 네트워크 생성에 필요한 정보들을 담고 있음 \n",
    "        \"\"\"\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.n_users = cfg.n_users\n",
    "        self.n_items = cfg.n_items\n",
    "        self.emb_dim = cfg.emb_dim\n",
    "        self.layer_dim = cfg.layer_dim\n",
    "        self.n_continuous_feats = cfg.n_continuous_feats\n",
    "        self.n_genres = cfg.n_genres\n",
    "        self.dropout = cfg.dropout\n",
    "        self.build_graph()\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Neural Matrix Factorization Model 생성\n",
    "            구현된 모습은 위의 그림을 참고 \n",
    "        \"\"\"\n",
    "        self.user_embedding_mf = nn.Embedding(num_embeddings=self.n_users, embedding_dim=self.emb_dim)\n",
    "        self.item_embedding_mf = nn.Embedding(num_embeddings=self.n_items, embedding_dim=self.emb_dim)\n",
    "        \n",
    "        self.user_embedding_mlp = nn.Embedding(num_embeddings=self.n_users, embedding_dim=self.emb_dim)\n",
    "        self.item_embedding_mlp = nn.Embedding(num_embeddings=self.n_items, embedding_dim=self.emb_dim)\n",
    "                \n",
    "        self.genre_embeddig = nn.Embedding(num_embeddings=self.n_genres, embedding_dim=self.n_genres//2)\n",
    "        \n",
    "        self.mlp_layers = nn.Sequential(\n",
    "            nn.Linear(2*self.emb_dim + self.n_genres//2 + self.n_continuous_feats, self.layer_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(p=self.dropout), \n",
    "            nn.Linear(self.layer_dim, self.layer_dim//2), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(p=self.dropout)\n",
    "        )\n",
    "        self.affine_output = nn.Linear(self.layer_dim//2 + self.emb_dim, 1)\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            normal_(module.weight.data, mean=0.0, std=0.01)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            normal_(module.weight.data, 0, 0.01)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.fill_(0.0)\n",
    "    \n",
    "    def forward(self, user_indices, item_indices, feats):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            user_indices : 유저의 인덱스 정보 \n",
    "                ex) tensor([ 3100,  3100,  ..., 14195, 14195])\n",
    "            item_indices : 아이템의 인덱스 정보\n",
    "                ex) tensor([   50,    65,   ..., 14960, 11527])\n",
    "            feats : 특징 정보 \n",
    "        Returns: \n",
    "            output : 유저-아이템 쌍에 대한 추천 결과 \n",
    "                ex) tensor([  9.4966,  22.0261, ..., -19.3535, -23.0212])\n",
    "        \"\"\"\n",
    "        user_embedding_mf = self.user_embedding_mf(user_indices)\n",
    "        item_embedding_mf = self.item_embedding_mf(item_indices)\n",
    "        mf_output = torch.mul(user_embedding_mf, item_embedding_mf)\n",
    "        \n",
    "        user_embedding_mlp = self.user_embedding_mlp(user_indices)\n",
    "        item_embedding_mlp = self.item_embedding_mlp(item_indices)\n",
    "        genre_embedding_mlp = self.genre_embeddig(feats[1])\n",
    "        input_feature = torch.cat((user_embedding_mlp, item_embedding_mlp, genre_embedding_mlp, feats[0].unsqueeze(1)), -1)\n",
    "        mlp_output = self.mlp_layers(input_feature)\n",
    "        \n",
    "        output = torch.cat([mlp_output, mf_output], dim=-1)\n",
    "        output = self.affine_output(output).squeeze(-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hE7ZtudJYU1V"
   },
   "source": [
    "### 학습 및 추론 코드 구현\n",
    "\n",
    "- 학습 : Negative sampling을 활용하여 Binary Classification 진행 \n",
    "    - history 에 있는 album_id는 positive label로 그렇지 않은 album_id는 nagative label로 활용  \n",
    "    - 단, 이때 모든 album_id를 negative label로 활용하는 것이 아닌 일부만 사용 (neg_ratio 값에 따라서 개수 조정)\n",
    "- 추론 : 일부 데이터에 대해 recall, ndcg, coverage 성능 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGTiX3PsYU1V"
   },
   "source": [
    "#### 학습 및 추론에 필요한 데이터 셋 생성 코드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_UIdataset(train, neg_ratio):\n",
    "    \"\"\" 유저별 학습에 필요한 딕셔너리 데이터 생성 \n",
    "    Args:\n",
    "        train : 유저-아이템의 상호작용을 담은 행렬 \n",
    "            ex) \n",
    "                array([[0., 0., 0., ..., 0., 0., 0.],\n",
    "                        [0., 0., 0., ..., 0., 0., 0.],\n",
    "                        [0., 0., 0., ..., 0., 0., 0.],\n",
    "                        ...,\n",
    "                        [0., 0., 0., ..., 0., 0., 0.],\n",
    "                        [0., 0., 0., ..., 0., 0., 0.],\n",
    "                        [0., 0., 0., ..., 0., 0., 0.]])\n",
    "        neg_ratio : negative sampling 활용할 비율 \n",
    "            ex) 3 (positive label 1개당 negative label 3개)\n",
    "    Returns: \n",
    "        UIdataset : 유저별 학습에 필요한 정보를 담은 딕셔너리 \n",
    "            ex) {'사용자 ID': [[positive 샘플, negative 샘플], ... , [1, 1, 1, ..., 0, 0]]}\n",
    "                >>> UIdataset[3]\n",
    "                    [array([   16,    17,    18, ...,  9586, 18991,  9442]),\n",
    "                    array([5, 5, 5, ..., 5, 5, 5]),\n",
    "                    array([4, 4, 4, ..., 5, 1, 1]),\n",
    "                    array([1., 1., 1., ..., 0., 0., 0.])]\n",
    "    \"\"\"\n",
    "    UIdataset = {}\n",
    "    for user_id, items_by_user in enumerate(train):\n",
    "        UIdataset[user_id] = []\n",
    "        # positive 샘플 계산 \n",
    "        pos_item_ids = np.where(items_by_user > 0.5)[0]\n",
    "        num_pos_samples = len(pos_item_ids)\n",
    "\n",
    "        # negative 샘플 계산 (random negative sampling) \n",
    "        num_neg_samples = neg_ratio * num_pos_samples\n",
    "        neg_items = np.where(items_by_user < 0.5)[0]\n",
    "        neg_item_ids = np.random.choice(neg_items, min(num_neg_samples, len(neg_items)), replace=False)\n",
    "        UIdataset[user_id].append(np.concatenate([pos_item_ids, neg_item_ids]))\n",
    "        \n",
    "        # feature 추출 \n",
    "        features = []\n",
    "        for item_id in np.concatenate([pos_item_ids, neg_item_ids]): \n",
    "            features.append(user_features['age'][user_id])\n",
    "        UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "        features = []\n",
    "        for item_id in np.concatenate([pos_item_ids, neg_item_ids]): \n",
    "            features.append(item_features['genre_mid'][item_id])\n",
    "        UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "        # label 저장  \n",
    "        pos_labels = np.ones(len(pos_item_ids))\n",
    "        neg_labels = np.zeros(len(neg_item_ids))\n",
    "        UIdataset[user_id].append(np.concatenate([pos_labels, neg_labels]))\n",
    "\n",
    "    return UIdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "UIdataset = make_UIdataset(train, neg_ratio=cfg.neg_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batchdata(user_indices, batch_idx, batch_size):\n",
    "    \"\"\" 배치 데이터로 변환 \n",
    "    Args:\n",
    "        user_indices : 전체 유저의 인덱스 정보 \n",
    "            ex) array([ 3100,  1800, 30098, ...,  2177, 11749, 20962])\n",
    "        batch_idx : 배치 인덱스 (몇번째 배치인지)\n",
    "            ex) 0 \n",
    "        batch_size : 배치 크기 \n",
    "            ex) 256 \n",
    "    Returns \n",
    "        batch_user_ids : 배치내의 유저 인덱스 정보 \n",
    "            ex) [22194, 22194, 22194, 22194, 22194, ...]\n",
    "        batch_item_ids : 배치내의 아이템 인덱스 정보 \n",
    "            ex) [36, 407, 612, 801, 1404, ...]\n",
    "        batch_feat0 : 배치내의 유저-아이템 인덱스 정보에 해당하는 feature0 정보 \n",
    "            ex) [6, 6, 6, 6, 6, ...]\n",
    "        batch_feat1 : 배치내의 유저-아이템 인덱스 정보에 해당하는 feature1 정보 \n",
    "            ex) [4,  4,  4, 23,  4, ...]\n",
    "        batch_labels : 배치내의 유저-아이템 인덱스 정보에 해당하는 label 정보 \n",
    "            ex) [1.0, 1.0, 1.0, 1.0, 1.0, ...]\n",
    "    \"\"\"\n",
    "    batch_user_indices = user_indices[batch_idx*batch_size : (batch_idx+1)*batch_size]\n",
    "    batch_user_ids = []\n",
    "    batch_item_ids = []\n",
    "    batch_feat0 = []\n",
    "    batch_feat1 = []\n",
    "    batch_labels = []\n",
    "    for user_id in batch_user_indices:\n",
    "        item_ids = UIdataset[user_id][0]\n",
    "        feat0 = UIdataset[user_id][1]\n",
    "        feat1 = UIdataset[user_id][2]\n",
    "        labels = UIdataset[user_id][3]\n",
    "        user_ids = np.full(len(item_ids), user_id)\n",
    "        batch_user_ids.extend(user_ids.tolist())\n",
    "        batch_item_ids.extend(item_ids.tolist())\n",
    "        batch_feat0.extend(feat0.tolist())\n",
    "        batch_feat1.extend(feat1.tolist())\n",
    "        batch_labels.extend(labels.tolist())\n",
    "    return batch_user_ids, batch_item_ids, batch_feat0, batch_feat1, batch_labels\n",
    "\n",
    "def update_avg(curr_avg, val, idx):\n",
    "    \"\"\" 현재 epoch 까지의 평균 값을 계산 \n",
    "    \"\"\"\n",
    "    return (curr_avg * idx + val) / (idx + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 및 검증 코드 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "dS1EPRpeYU1W"
   },
   "outputs": [],
   "source": [
    "def train_epoch(cfg, model, optimizer, criterion): \n",
    "    model.train()\n",
    "    curr_loss_avg = 0.0\n",
    "\n",
    "    user_indices = np.arange(cfg.n_users)\n",
    "    np.random.RandomState(cfg.epoch).shuffle(user_indices)\n",
    "    batch_num = int(len(user_indices) / cfg.batch_size) + 1\n",
    "    bar = tqdm(range(batch_num), leave=False)\n",
    "    for step, batch_idx in enumerate(bar):\n",
    "        user_ids, item_ids, feat0, feat1, labels = make_batchdata(user_indices, batch_idx, cfg.batch_size)\n",
    "        # 배치 사용자 단위로 학습\n",
    "        user_ids = torch.LongTensor(user_ids).to(cfg.device)\n",
    "        item_ids = torch.LongTensor(item_ids).to(cfg.device)\n",
    "        feat0 = torch.FloatTensor(feat0).to(cfg.device)\n",
    "        feat1 = torch.LongTensor(feat1).to(cfg.device)\n",
    "        labels = torch.FloatTensor(labels).to(cfg.device)\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        # grad 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 모델 forward\n",
    "        output = model.forward(user_ids, item_ids, [feat0, feat1])\n",
    "        output = output.view(-1, 1)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "\n",
    "        # 최적화\n",
    "        optimizer.step()    \n",
    "        if torch.isnan(loss):\n",
    "            print('Loss NAN. Train finish.')\n",
    "            break\n",
    "        curr_loss_avg = update_avg(curr_loss_avg, loss, step)\n",
    "        \n",
    "        msg = f\"epoch: {cfg.epoch}, \"\n",
    "        msg += f\"loss: {curr_loss_avg.item():.5f}, \"\n",
    "        msg += f\"lr: {optimizer.param_groups[0]['lr']:.6f}\"\n",
    "        bar.set_description(msg)\n",
    "    rets = {'losses': np.around(curr_loss_avg.item(), 5)}\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recallk(actual, predicted, k = 25):\n",
    "    \"\"\" label과 prediction 사이의 recall 평가 함수 \n",
    "    Args:\n",
    "        actual : 실제로 본 상품 리스트\n",
    "        pred : 예측한 상품 리스트\n",
    "        k : 상위 몇개의 데이터를 볼지 (ex : k=5 상위 5개의 상품만 봄)\n",
    "    Returns: \n",
    "        recall_k : recall@k \n",
    "    \"\"\" \n",
    "    set_actual = set(actual)\n",
    "    recall_k = len(set_actual & set(predicted[:k])) / min(k, len(set_actual))\n",
    "    return recall_k\n",
    "\n",
    "def unique(sequence):\n",
    "    # preserves order\n",
    "    seen = set()\n",
    "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
    "\n",
    "def ndcgk(actual, predicted, k = 25):\n",
    "    set_actual = set(actual)\n",
    "    idcg = sum([1.0 / np.log(i + 2) for i in range(min(k, len(set_actual)))])\n",
    "    dcg = 0.0\n",
    "    unique_predicted = unique(predicted[:k])\n",
    "    for i, r in enumerate(unique_predicted):\n",
    "        if r in set_actual:\n",
    "            dcg += 1.0 / np.log(i + 2)\n",
    "    ndcg_k = dcg / idcg\n",
    "    return ndcg_k\n",
    "\n",
    "def evaluation(gt, pred):\n",
    "    \"\"\" label과 prediction 사이의 recall, coverage, competition metric 평가 함수 \n",
    "    Args:\n",
    "        gt : 데이터 프레임 형태의 정답 데이터 \n",
    "        pred : 데이터 프레임 형태의 예측 데이터 \n",
    "    Returns: \n",
    "        rets : recall, ndcg, coverage, competition metric 결과 \n",
    "            ex) {'recall': 0.123024, 'ndcg': 056809, 'coverage': 0.017455, 'score': 0.106470}\n",
    "    \"\"\"    \n",
    "    gt = gt.groupby('profile_id')['album_id'].unique().to_frame().reset_index()\n",
    "    gt.columns = ['profile_id', 'actual_list']\n",
    "\n",
    "    evaluated_data = pd.merge(pred, gt, how = 'left', on = 'profile_id')\n",
    "\n",
    "    evaluated_data['Recall@25'] = evaluated_data.apply(lambda x: recallk(x.actual_list, x.predicted_list), axis=1)\n",
    "    evaluated_data['NDCG@25'] = evaluated_data.apply(lambda x: ndcgk(x.actual_list, x.predicted_list), axis=1)\n",
    "\n",
    "    recall = evaluated_data['Recall@25'].mean()\n",
    "    ndcg = evaluated_data['NDCG@25'] .mean()\n",
    "    coverage = (evaluated_data['predicted_list'].apply(lambda x: x[:cfg.top_k]).explode().nunique())/meta_df.index.nunique()\n",
    "\n",
    "    score = 0.75*recall + 0.25*ndcg\n",
    "    rets = {\"recall\" :recall, \n",
    "            \"ndcg\" :ndcg, \n",
    "            \"coverage\" :coverage, \n",
    "            \"score\" :score}\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FQgUJbTOYU1X"
   },
   "outputs": [],
   "source": [
    "def valid_epoch(cfg, model, data, mode='valid'):\n",
    "    pred_list = []\n",
    "    model.eval()\n",
    "    \n",
    "    query_user_ids = data['profile_id'].unique() # 추론할 모든 user array 집합\n",
    "    full_item_ids = np.array([c for c in range(cfg.n_items)]) # 추론할 모든 item array 집합 \n",
    "    full_item_ids_feat1 = [item_features['genre_mid'][c] for c in full_item_ids]\n",
    "    for user_id in query_user_ids:\n",
    "        with torch.no_grad():\n",
    "            user_ids = np.full(cfg.n_items, user_id)\n",
    "            \n",
    "            user_ids = torch.LongTensor(user_ids).to(cfg.device)\n",
    "            item_ids = torch.LongTensor(full_item_ids).to(cfg.device)\n",
    "            \n",
    "            feat0 = np.full(cfg.n_items, user_features['age'][user_id])\n",
    "            feat0 = torch.FloatTensor(feat0).to(cfg.device)\n",
    "            feat1 = torch.LongTensor(full_item_ids_feat1).to(cfg.device)\n",
    "            \n",
    "            eval_output = model.forward(user_ids, item_ids, [feat0, feat1]).detach().cpu().numpy()\n",
    "            pred_u_score = eval_output.reshape(-1)   \n",
    "        \n",
    "        pred_u_idx = np.argsort(pred_u_score)[::-1]\n",
    "        pred_u = full_item_ids[pred_u_idx]\n",
    "        pred_list.append(list(pred_u[:cfg.top_k]))\n",
    "        \n",
    "    pred = pd.DataFrame()\n",
    "    pred['profile_id'] = query_user_ids\n",
    "    pred['predicted_list'] = pred_list\n",
    "    \n",
    "    # 모델 성능 확인 \n",
    "    if mode == 'valid':\n",
    "        rets = evaluation(data, pred)\n",
    "        return rets, pred\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-D5bJx7YU1X"
   },
   "source": [
    "### 하이퍼파라미터 설정 & 최적화 기법 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정 \n",
    "cfg.batch_size = 256\n",
    "cfg.emb_dim = 256\n",
    "cfg.layer_dim = 256\n",
    "cfg.dropout = 0.05\n",
    "cfg.epochs = 25\n",
    "cfg.learning_rate = 0.0025\n",
    "cfg.reg_lambda = 0\n",
    "cfg.check_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 생성 및 optimizer, loss 함수 설정 \n",
    "model = NeuMF(cfg).to(cfg.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate, weight_decay=cfg.reg_lambda)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eze0e7vtYU1Y"
   },
   "source": [
    "### 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "cvhj3hD7YU1Y",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch,Train Loss,Valid Recall@25,Valid NDCG@25,Valid Coverage,Valid Score\n",
      "00  10499.767580  0.174039  0.134841  0.001931  0.164240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01  9413.085940  0.253257  0.194916  0.016176  0.238672\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f55f7fcf21d40bbb9123ba4c0f83bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 602.00 MiB (GPU 0; 6.00 GiB total capacity; 4.57 GiB already allocated; 0 bytes free; 4.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [34], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cfg\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      4\u001b[0m     cfg\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch\n\u001b[1;32m----> 5\u001b[0m     train_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# cfg.check_epoch 번의 epoch 마다 성능 확인 \u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m cfg\u001b[38;5;241m.\u001b[39mcheck_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \n",
      "Cell \u001b[1;32mIn [16], line 23\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(cfg, model, optimizer, criterion)\u001b[0m\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 모델 forward\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeat0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n",
      "Cell \u001b[1;32mIn [12], line 78\u001b[0m, in \u001b[0;36mNeuMF.forward\u001b[1;34m(self, user_indices, item_indices, feats)\u001b[0m\n\u001b[0;32m     75\u001b[0m input_feature \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((user_embedding_mlp, item_embedding_mlp, genre_embedding_mlp, feats[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     76\u001b[0m mlp_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_layers(input_feature)\n\u001b[1;32m---> 78\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmlp_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmf_output\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffine_output(output)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 602.00 MiB (GPU 0; 6.00 GiB total capacity; 4.57 GiB already allocated; 0 bytes free; 4.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "total_logs = defaultdict(list)\n",
    "best_scores  = 0\n",
    "for epoch in range(cfg.epochs+1):\n",
    "    cfg.epoch = epoch\n",
    "    train_results = train_epoch(cfg, model, optimizer, criterion)\n",
    "    \n",
    "    # cfg.check_epoch 번의 epoch 마다 성능 확인 \n",
    "    if epoch % cfg.check_epoch == 0: \n",
    "        valid_results, _ = valid_epoch(cfg, model, valid)\n",
    "\n",
    "        logs = {\n",
    "            'Train Loss': train_results['losses'],\n",
    "            f'Valid Recall@{cfg.top_k}': valid_results['recall'],\n",
    "            f'Valid NDCG@{cfg.top_k}': valid_results['ndcg'],\n",
    "            'Valid Coverage': valid_results['coverage'],\n",
    "            'Valid Score': valid_results['score'],\n",
    "            }\n",
    "\n",
    "        # 검증 성능 확인 \n",
    "        for key, value in logs.items():\n",
    "            total_logs[key].append(value)\n",
    "\n",
    "        if epoch == 0:\n",
    "            print(\"Epoch\", end=\",\")\n",
    "            print(\",\".join(logs.keys()))\n",
    "\n",
    "        print(f\"{epoch:02d}  \", end=\"\")\n",
    "        print(\"  \".join([f\"{v:0.6f}\" for v in logs.values()]))\n",
    "        \n",
    "        # 가장 성능이 좋은 가중치 파일을 저장 \n",
    "        if best_scores <= valid_results['score']: \n",
    "            best_scores = valid_results['score']\n",
    "            torch.save(model.state_dict(), os.path.join(saved_path, 'model(best_scores).pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n",
      "0.14.0\n",
      "0.13.0\n"
     ]
    }
   ],
   "source": [
    "import torchvision, torchaudio\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# DEVICE 0: NVIDIA GeForce GTX 1060 6GB\n",
      "- Memory Usage:\n",
      "  Allocated: 0.5 GB\n",
      "  Cached:    0.5 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"# DEVICE {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(\"- Memory Usage:\")\n",
    "        print(f\"  Allocated: {round(torch.cuda.memory_allocated(i)/1024**3,1)} GB\")\n",
    "        print(f\"  Cached:    {round(torch.cuda.memory_cached(i)/1024**3,1)} GB\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"# GPU is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNVpn37RYU1Z"
   },
   "source": [
    "### 학습 과정 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = pd.DataFrame({'Train loss': total_logs['Train Loss']})\n",
    "train_scores['Epoch'] = range(0, cfg.epochs+1, cfg.check_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(train_scores, aes(x='Epoch', y='Train loss'))\n",
    "        + geom_line(color='black') # line plot\n",
    "        + labs(x='Epoch', y='Train Loss')\n",
    "        + theme_light()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_scores = pd.DataFrame(np.hstack([(range(0, cfg.epochs+1, cfg.check_epoch), total_logs[score], [score for i in range(0, cfg.epochs+1, cfg.check_epoch)]) for score in ['Valid Recall@25', 'Valid NDCG@25', 'Valid Coverage', 'Valid Score']])).T\n",
    "valid_scores.columns = ['Epoch', 'Score', 'Metric']\n",
    "valid_scores['Epoch'] = valid_scores['Epoch'].astype(int)\n",
    "valid_scores['Score'] = valid_scores['Score'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "ggplot(valid_scores)  # here\n",
    "    + aes(\"Epoch\", \"Score\", color='Metric', group='Metric')\n",
    "    + geom_line()\n",
    "    + scale_y_continuous(breaks=[0.1*c for c in range(1, 10, 1)])\n",
    "    + theme_light()\n",
    "    + labs(x='Epoch', y='Valid Metric')\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07lHW5CAYU1F"
   },
   "source": [
    "## 제출 \n",
    "### 모든 유저에 대해 추천 결과 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(saved_path, 'model(best_scores).pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = os.path.join(data_path, 'sample_submission.csv')\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission = valid_epoch(cfg, model, submission, mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(output_path, 'submission.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "기본과제-2_NCF+AutoRec (answer).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1dbd43fe9b6ac5035e713bc64837ed61b2c8b42edd7497e359f007ee89da5e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
