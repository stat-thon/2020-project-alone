{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미래에셋 빅데이터 콘테스트\n",
    "# \n",
    "### 보험금 청구 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주성분분석을 사용한 차원축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " RandomForestClassifier,BaggingClassifier,GradientBoostingClassifier,AdaBoostClassifier, KNeighborsClassifier, MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_csv(\"D:/thon/data/mirae/classification/sample.csv\")\n",
    "train = pd.read_csv(\"D:/thon/data/mirae/classification/train.csv\")\n",
    "test = pd.read_csv(\"D:/thon/data/mirae/classification/test.csv\")\n",
    "train_dummy = pd.read_csv(\"D:/thon/data/mirae/classification/train_dummy.csv\")\n",
    "test_dummy = pd.read_csv(\"D:/thon/data/mirae/classification/test_dummy.csv\")\n",
    "train_wo_uk_dummy = pd.read_csv(\"D:/thon/data/mirae/classification/train_uk_dummy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsp_avg_optt_bilg_isamt_s</th>\n",
       "      <th>hsp_avg_surop_bilg_isamt_s</th>\n",
       "      <th>hspz_dys_s</th>\n",
       "      <th>hsp_avg_diag_bilg_isamt_s</th>\n",
       "      <th>dsas_avg_diag_bilg_isamt_s</th>\n",
       "      <th>base_ym</th>\n",
       "      <th>hsp_avg_hspz_bilg_isamt_s</th>\n",
       "      <th>optt_blcnt_s</th>\n",
       "      <th>surop_blcnt_s</th>\n",
       "      <th>dsas_avg_optt_bilg_isamt_s</th>\n",
       "      <th>...</th>\n",
       "      <th>isrd_age_dcd_7</th>\n",
       "      <th>isrd_age_dcd_9</th>\n",
       "      <th>urlb_fc_yn_1</th>\n",
       "      <th>smrtg_5y_passed_yn_1</th>\n",
       "      <th>ac_rst_diff_1</th>\n",
       "      <th>ac_rst_diff_2</th>\n",
       "      <th>ac_rst_diff_3</th>\n",
       "      <th>ac_rst_diff_4</th>\n",
       "      <th>ac_rst_diff_5</th>\n",
       "      <th>ac_rst_diff_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2938</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>201912</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0548</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5266</td>\n",
       "      <td>2.1745</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3936</td>\n",
       "      <td>1.1121</td>\n",
       "      <td>201912</td>\n",
       "      <td>0.7517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.6061</td>\n",
       "      <td>1.6884</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0524</td>\n",
       "      <td>1.1091</td>\n",
       "      <td>201912</td>\n",
       "      <td>1.2090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.1593</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>1.1091</td>\n",
       "      <td>201912</td>\n",
       "      <td>0.2785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2660</td>\n",
       "      <td>1.1593</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>201912</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22067</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>201912</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22068</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5815</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>201912</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22069</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>201912</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22070</th>\n",
       "      <td>1.7263</td>\n",
       "      <td>1.8482</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>201912</td>\n",
       "      <td>1.3442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22071</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3336</td>\n",
       "      <td>0.1713</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>201912</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22072 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hsp_avg_optt_bilg_isamt_s  hsp_avg_surop_bilg_isamt_s  hspz_dys_s  \\\n",
       "0                         0.0000                      0.2938      0.0000   \n",
       "1                         1.5266                      2.1745      0.0000   \n",
       "2                         1.6061                      1.6884      0.0000   \n",
       "3                         0.1228                      0.8927      0.1847   \n",
       "4                         0.0000                      0.2440      0.0000   \n",
       "...                          ...                         ...         ...   \n",
       "22067                     0.0000                      0.1975      0.0000   \n",
       "22068                     0.0000                      0.5815      0.0000   \n",
       "22069                     0.0000                      0.0741      0.0000   \n",
       "22070                     1.7263                      1.8482      0.0000   \n",
       "22071                     0.0000                      0.3336      0.1713   \n",
       "\n",
       "       hsp_avg_diag_bilg_isamt_s  dsas_avg_diag_bilg_isamt_s  base_ym  \\\n",
       "0                         0.0000                      0.0000   201912   \n",
       "1                         1.3936                      1.1121   201912   \n",
       "2                         1.0524                      1.1091   201912   \n",
       "3                         0.3889                      1.1091   201912   \n",
       "4                         0.0000                      0.0000   201912   \n",
       "...                          ...                         ...      ...   \n",
       "22067                     0.0000                      0.0000   201912   \n",
       "22068                     0.0000                      0.0000   201912   \n",
       "22069                     0.0000                      0.0000   201912   \n",
       "22070                     0.8596                      0.8077   201912   \n",
       "22071                     0.0000                      0.0000   201912   \n",
       "\n",
       "       hsp_avg_hspz_bilg_isamt_s  optt_blcnt_s  surop_blcnt_s  \\\n",
       "0                         0.0000           0.0         1.0548   \n",
       "1                         0.7517           0.0         1.0000   \n",
       "2                         1.2090           0.0         0.0000   \n",
       "3                         0.2785           0.0         1.2660   \n",
       "4                         0.0000           0.0         1.0000   \n",
       "...                          ...           ...            ...   \n",
       "22067                     0.0267           0.0         1.0000   \n",
       "22068                     0.9098           0.0         0.0000   \n",
       "22069                     0.0000           0.0         2.0000   \n",
       "22070                     1.3442           0.0         0.6732   \n",
       "22071                     0.2458           0.0         1.0000   \n",
       "\n",
       "       dsas_avg_optt_bilg_isamt_s  ...  isrd_age_dcd_7  isrd_age_dcd_9  \\\n",
       "0                          0.0000  ...               0               0   \n",
       "1                          0.5200  ...               0               0   \n",
       "2                          1.1593  ...               0               0   \n",
       "3                          1.1593  ...               0               0   \n",
       "4                          0.0000  ...               0               0   \n",
       "...                           ...  ...             ...             ...   \n",
       "22067                      0.0000  ...               0               0   \n",
       "22068                      0.0000  ...               0               0   \n",
       "22069                      0.0000  ...               0               0   \n",
       "22070                      0.8690  ...               0               0   \n",
       "22071                      0.0000  ...               0               0   \n",
       "\n",
       "       urlb_fc_yn_1  smrtg_5y_passed_yn_1  ac_rst_diff_1  ac_rst_diff_2  \\\n",
       "0                 0                     0              0              0   \n",
       "1                 0                     0              0              0   \n",
       "2                 0                     0              0              0   \n",
       "3                 0                     0              0              0   \n",
       "4                 0                     0              0              0   \n",
       "...             ...                   ...            ...            ...   \n",
       "22067             0                     0              0              0   \n",
       "22068             0                     0              0              0   \n",
       "22069             0                     0              0              0   \n",
       "22070             0                     0              0              0   \n",
       "22071             0                     0              0              0   \n",
       "\n",
       "       ac_rst_diff_3  ac_rst_diff_4  ac_rst_diff_5  ac_rst_diff_6  \n",
       "0                  0              0              0              0  \n",
       "1                  0              0              0              0  \n",
       "2                  0              0              0              0  \n",
       "3                  0              0              0              0  \n",
       "4                  0              0              0              0  \n",
       "...              ...            ...            ...            ...  \n",
       "22067              0              0              0              0  \n",
       "22068              0              0              0              1  \n",
       "22069              0              0              0              0  \n",
       "22070              0              0              0              0  \n",
       "22071              0              0              0              1  \n",
       "\n",
       "[22072 rows x 126 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dummy.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "test_dummy.drop(['ID'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1% 시험 수행 준비\n",
    "t1 = train_dummy.sample(frac = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y 구분\n",
    "x_t1 = t1.drop(['target'], axis = 1)\n",
    "y_t1 = t1['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#타깃 변수 문자형으로 변환\n",
    "y_t1 = y_t1.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특성행렬 표준화\n",
    "t1_features = StandardScaler().fit_transform(x_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#99% 분산을 유지하도록 PCA 클래스 객체 생성\n",
    "pca = PCA(n_components = 0.99, whiten = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca 수행\n",
    "t1_features_pca = pca.fit_transform(t1_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 특성 개수: 129\n",
      "줄어든 특성 개수: 105\n"
     ]
    }
   ],
   "source": [
    "#결과 확인\n",
    "print(\"원본 특성 개수:\", t1_features.shape[1])\n",
    "print(\"줄어든 특성 개수:\", t1_features_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#표준화 객체 생성\n",
    "standardizer = StandardScaler()\n",
    "#로지스틱회귀 객체 생성\n",
    "logit = LogisticRegression()\n",
    "#표준화 후 로지스틱 회귀를 실행하는 파이프라인 생성\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "#k-fold 교차검증 만들기\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#k-fold CV 수행\n",
    "t1_cv_results = cross_val_score(pipeline, #파이프라인\n",
    "                            t1_features_pca,#특성 행렬\n",
    "                            y_t1, #타깃 벡터\n",
    "                            cv = kf,      #교차검증 기법\n",
    "                            scoring = 'accuracy', #평가 지표\n",
    "                            n_jobs = -1)   #모든 CPU코어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8929167874259167"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련, 테스트 데이터로 나누기\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_t1, y_t1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733305111652026"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#랜덤포레스트\n",
    "classifier_randomforest = RandomForestClassifier()\n",
    "classifier_randomforest.fit(x_train, y_train)\n",
    "classifier_randomforest.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 훈련하고 예측 결과 계산\n",
    "target_pred = classifier_randomforest.fit(x_train, y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#오차행렬 생성\n",
    "matrix = confusion_matrix(y_test, target_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터프레임 생성\n",
    "df = pd.DataFrame(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df, annot = True, cbar = None, cmap = 'Blues')\n",
    "plt.title(\"confusion matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"true class\"), plt.xlabel('predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9710022224574029"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#배깅\n",
    "classifier_bagging = BaggingClassifier()\n",
    "classifier_bagging.fit(x_train, y_train)\n",
    "classifier_bagging.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9511059371362048"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoost\n",
    "classifier_adaboost = AdaBoostClassifier()\n",
    "classifier_adaboost.fit(x_train, y_train)\n",
    "classifier_adaboost.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9729071859456027"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gradientboost\n",
    "classifier_gradientboost = GradientBoostingClassifier()\n",
    "classifier_gradientboost.fit(x_train, y_train)\n",
    "classifier_gradientboost.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9663456450418033"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#knn\n",
    "classifier_knn = KNeighborsClassifier()\n",
    "classifier_knn.fit(x_train, y_train)\n",
    "classifier_knn.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8527886548841147"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MLP\n",
    "classifier_mlp = MLPClassifier()\n",
    "classifier_mlp.fit(x_train, y_train)\n",
    "classifier_mlp.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [RandomForestClassifier(),BaggingClassifier(),GradientBoostingClassifier(),\n",
    "          AdaBoostClassifier(), KNeighborsClassifier(), MLPClassifier()]\n",
    "model_names = ['RandomForest', 'Bagging', 'GradientBoosting', 'AdaBoost', 'KNN', 'MLP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    model.score(x_test, y_test)\n",
    "\n",
    "d = {'ModelAlgorithm':model_names, 'accuracy': model.score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ModelAlgorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>&lt;bound method ClassifierMixin.score of MLPClas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>&lt;bound method ClassifierMixin.score of MLPClas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>&lt;bound method ClassifierMixin.score of MLPClas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>&lt;bound method ClassifierMixin.score of MLPClas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>&lt;bound method ClassifierMixin.score of MLPClas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>&lt;bound method ClassifierMixin.score of MLPClas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ModelAlgorithm                                           accuracy\n",
       "0      RandomForest  <bound method ClassifierMixin.score of MLPClas...\n",
       "1           Bagging  <bound method ClassifierMixin.score of MLPClas...\n",
       "2  GradientBoosting  <bound method ClassifierMixin.score of MLPClas...\n",
       "3          AdaBoost  <bound method ClassifierMixin.score of MLPClas...\n",
       "4               KNN  <bound method ClassifierMixin.score of MLPClas...\n",
       "5               MLP  <bound method ClassifierMixin.score of MLPClas..."
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요없는 칼럼 제거\n",
    "train_dummy.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "train_wo_uk_dummy.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "train_dummy.drop(['ID'], axis = 1, inplace = True)\n",
    "train_wo_uk_dummy.drop(['ID'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X와 Y로 변수 구별\n",
    "x_train_dummy = train_dummy.drop(['target'], axis = 1)\n",
    "y_train_dummy = train_dummy['target']\n",
    "x_train_wo_uk_dummy = train_wo_uk_dummy.drop(['target'], axis = 1)\n",
    "y_train_wo_uk_dummy = train_wo_uk_dummy['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#타깃 변수 문자형 변환\n",
    "y_train_dummy = y_train_dummy.astype(str)\n",
    "y_train_wo_uk_dummy = y_train_wo_uk_dummy.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특성 행렬 표준화 처리\n",
    "train_features = StandardScaler().fit_transform(x_train_dummy)\n",
    "train_wo_uk_features = StandardScaler().fit_transform(x_train_wo_uk_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#99% 분산을 유지하도록 PCA 클래스 객체 생성\n",
    "pca = PCA(n_components = 0.99, whiten = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA 수행\n",
    "train_features_pca = pca.fit_transform(train_features)\n",
    "train_wo_uk_features_pca = pca.fit_transform(train_wo_uk_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 특성 개수: 127 135\n",
      "줄어든 특성 개수: 104 100\n"
     ]
    }
   ],
   "source": [
    "#결과 확인\n",
    "print(\"원본 특성 개수:\", train_features.shape[1], train_wo_uk_features.shape[1])\n",
    "print(\"줄어든 특성 개수:\", train_features_pca.shape[1], train_wo_uk_features_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#표준화 객체 생성\n",
    "standardizer = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#로지스틱회귀 객체 생성\n",
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#표준화 후 로지스틱 회귀를 실행하는 파이프라인 생성\n",
    "pipeline = make_pipeline(standardizer, logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-fold 교차검증 만들기\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thon\\anaconda3\\envs\\thon\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#k-fold CV 수행\n",
    "cv_results = cross_val_score(pipeline, #파이프라인\n",
    "                            train_features_pca,#특성 행렬\n",
    "                            y_train_dummy, #타깃 벡터\n",
    "                            cv = kf,      #교차검증 기법\n",
    "                            scoring = 'accuracy', #평가 지표\n",
    "                            n_jobs = 1)   #모든 CPU코어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406013866580985"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
