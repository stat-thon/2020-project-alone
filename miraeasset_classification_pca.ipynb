{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미래에셋 빅데이터 콘테스트\n",
    "# \n",
    "### 보험금 청구 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주성분분석을 사용한 차원축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"D:/thon/data/mirae/classification/train.csv\")\n",
    "test = pd.read_csv(\"D:/thon/data/mirae/classification/test.csv\")\n",
    "train_dummy = pd.read_csv(\"D:/thon/data/mirae/classification/train_dummy.csv\")\n",
    "test_dummy = pd.read_csv(\"D:/thon/data/mirae/classification/test_dummy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요없는 항목 삭제\n",
    "test_dummy.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "test_dummy.drop(['ID'], axis = 1, inplace = True)\n",
    "test_dummy.drop(['base_ym'], axis = 1, inplace = True)\n",
    "\n",
    "train_dummy.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "train_dummy.drop(['ID'], axis = 1, inplace = True)\n",
    "train_dummy.drop(['base_ym'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y 구분\n",
    "x_train = train_dummy.drop(['target'], axis = 1)\n",
    "y_train = train_dummy['target']\n",
    "\n",
    "#타깃 변수 문자형으로 변환\n",
    "y_train = y_train.astype(str)\n",
    "\n",
    "#특성행렬 표준화\n",
    "train_features = StandardScaler().fit_transform(x_train)\n",
    "\n",
    "#99% 분산을 유지하도록 PCA 클래스 객체 생성\n",
    "pca = PCA(n_components = 0.99, whiten = True)\n",
    "\n",
    "#pca 수행\n",
    "train_features_pca = pca.fit_transform(train_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 특성 개수: 126\n",
      "줄어든 특성 개수: 103\n"
     ]
    }
   ],
   "source": [
    "#결과 확인\n",
    "print(\"원본 특성 개수:\", train_features.shape[1])\n",
    "print(\"줄어든 특성 개수:\", train_features_pca.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA 결과 feature를 126개에서 103개로 줄일 수 있었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#표준화 객체 생성\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "#로지스틱회귀 객체 생성\n",
    "logit = LogisticRegression()\n",
    "\n",
    "#표준화 후 로지스틱 회귀를 실행하는 파이프라인 생성\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "#k-fold 교차검증 만들기\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 1)\n",
    "\n",
    "#k-fold CV 수행\n",
    "t1_cv_results = cross_val_score(pipeline, #파이프라인\n",
    "                            t1_features_pca,#특성 행렬\n",
    "                            y_t1, #타깃 벡터\n",
    "                            cv = kf,      #교차검증 기법\n",
    "                            scoring = 'accuracy', #평가 지표\n",
    "                            n_jobs = -1)   #모든 CPU코어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8929167874259167"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV 회귀분석 결과 정확도 89.3%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
